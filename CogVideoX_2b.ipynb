{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO7tP1KKf8yPvgVl8z0VqqJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31b698e587364030bc0a51b356a5f1d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e352b3827702417098aedcd11c4256fa",
              "IPY_MODEL_1a43a3ae88ef4dabbcc4b092bbd716de",
              "IPY_MODEL_d008ced78b6948cc9b5a2312aca21b64"
            ],
            "layout": "IPY_MODEL_f0a6bccdafc848a9a0a200290cca73d5"
          }
        },
        "e352b3827702417098aedcd11c4256fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22421f7e11854b408dbbe06ab38308c7",
            "placeholder": "​",
            "style": "IPY_MODEL_48693660f6154dd1b77ec46789b3ed0a",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "1a43a3ae88ef4dabbcc4b092bbd716de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d862794c6b0b48ce9698bbfe2ce831f9",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df8035571e274d349265dedbca22ece0",
            "value": 5
          }
        },
        "d008ced78b6948cc9b5a2312aca21b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a95b8a23d3f8421cafb70b01e30742d9",
            "placeholder": "​",
            "style": "IPY_MODEL_51a6b943e1d7442cbc790c5863f94327",
            "value": " 5/5 [00:11&lt;00:00,  3.34s/it]"
          }
        },
        "f0a6bccdafc848a9a0a200290cca73d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22421f7e11854b408dbbe06ab38308c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48693660f6154dd1b77ec46789b3ed0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d862794c6b0b48ce9698bbfe2ce831f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df8035571e274d349265dedbca22ece0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a95b8a23d3f8421cafb70b01e30742d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a6b943e1d7442cbc790c5863f94327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1215a7adf96454c9d8e76dd14511c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eeac6bcaba6841a690faad33ff8665a6",
              "IPY_MODEL_438fba0787a1454aa84f90415ddff3ec",
              "IPY_MODEL_2f1aba318676413e878b7e88d6881578"
            ],
            "layout": "IPY_MODEL_ca9ddaa474a4495e9dc982aa158cf830"
          }
        },
        "eeac6bcaba6841a690faad33ff8665a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e7a3f46628449ee98d249bd566fb05a",
            "placeholder": "​",
            "style": "IPY_MODEL_2da07839b37348ba821945b49db3f012",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "438fba0787a1454aa84f90415ddff3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b90f21c1054e5d92a07c0a7a8d8a4b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_527e66130ea3431db230e364e1427d73",
            "value": 2
          }
        },
        "2f1aba318676413e878b7e88d6881578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee52cda6436a4fa7bc7a7f54877c8154",
            "placeholder": "​",
            "style": "IPY_MODEL_8ee637498d7b42e3be7efeeb3b4d12ee",
            "value": " 2/2 [00:10&lt;00:00,  4.95s/it]"
          }
        },
        "ca9ddaa474a4495e9dc982aa158cf830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e7a3f46628449ee98d249bd566fb05a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da07839b37348ba821945b49db3f012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89b90f21c1054e5d92a07c0a7a8d8a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527e66130ea3431db230e364e1427d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee52cda6436a4fa7bc7a7f54877c8154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee637498d7b42e3be7efeeb3b4d12ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayush1693/Text2Video-CogVideoX/blob/main/CogVideoX_2b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Colab Notebook: Text-to-Video Generation using CogVideo**\n",
        "\n",
        "\n",
        "---\n",
        "This notebook guides you through installing and using the CogVideo model for generating videos from text prompts. We will install the necessary libraries, set up the model, and then use it to generate a video based on a text description.\n"
      ],
      "metadata": {
        "id": "Vw2KCiSEqsSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Install Required Libraries\n",
        "In this step, we will clone the CogVideo repository and install the required Python packages."
      ],
      "metadata": {
        "id": "-Se6S9U2q5jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the CogVideo repository from GitHub\n",
        "!git clone https://github.com/THUDM/CogVideo\n",
        "\n",
        "# Install the required dependencies from the requirements.txt file\n",
        "!pip install -r CogVideo/requirements.txt\n",
        "\n",
        "# Install Hugging Face Hub for easy access to pre-trained models\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqciK191q-kI",
        "outputId": "b42a2024-0c9d-4edf-d88b-b6dfe5cb8459"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CogVideo' already exists and is not an empty directory.\n",
            "Requirement already satisfied: diffusers>=0.30.3 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 1)) (0.30.3)\n",
            "Requirement already satisfied: accelerate>=0.34.2 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 2)) (0.34.2)\n",
            "Requirement already satisfied: transformers>=4.44.2 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 3)) (4.44.2)\n",
            "Requirement already satisfied: numpy==1.26.0 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 4)) (1.26.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 5)) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 6)) (0.19.1+cu121)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: SwissArmyTransformer>=0.4.12 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 8)) (0.4.12)\n",
            "Requirement already satisfied: gradio>=4.44.0 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 9)) (5.1.0)\n",
            "Requirement already satisfied: imageio>=2.35.1 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 10)) (2.35.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: openai>=1.45.0 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 12)) (1.52.0)\n",
            "Requirement already satisfied: moviepy>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 13)) (1.0.3)\n",
            "Requirement already satisfied: pillow==9.5.0 in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 14)) (9.5.0)\n",
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.10/dist-packages (from -r CogVideo/requirements.txt (line 15)) (1.1.11)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.30.3->-r CogVideo/requirements.txt (line 1)) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.30.3->-r CogVideo/requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.30.3->-r CogVideo/requirements.txt (line 1)) (0.26.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.30.3->-r CogVideo/requirements.txt (line 1)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.30.3->-r CogVideo/requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.30.3->-r CogVideo/requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.2->-r CogVideo/requirements.txt (line 2)) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.2->-r CogVideo/requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.2->-r CogVideo/requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->-r CogVideo/requirements.txt (line 3)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->-r CogVideo/requirements.txt (line 3)) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->-r CogVideo/requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->-r CogVideo/requirements.txt (line 5)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->-r CogVideo/requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->-r CogVideo/requirements.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->-r CogVideo/requirements.txt (line 5)) (2024.6.1)\n",
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (0.15.2)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (2.6.2.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (3.0.1)\n",
            "Requirement already satisfied: cpm-kernels in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (1.0.11)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (0.8.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (1.35.44)\n",
            "Requirement already satisfied: webdataset in /usr/local/lib/python3.10/dist-packages (from SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (0.2.100)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.115.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.27.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (3.10.7)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.0.12)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.12.5)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.32.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.0->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.5.1->-r CogVideo/requirements.txt (line 11)) (75.1.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.45.0->-r CogVideo/requirements.txt (line 12)) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->-r CogVideo/requirements.txt (line 12)) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->-r CogVideo/requirements.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.3->-r CogVideo/requirements.txt (line 13)) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.3->-r CogVideo/requirements.txt (line 13)) (0.1.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video->-r CogVideo/requirements.txt (line 15)) (1.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.41.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.40.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers>=0.30.3->-r CogVideo/requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers>=0.30.3->-r CogVideo/requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (13.9.2)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.44 in /usr/local/lib/python3.10/dist-packages (from boto3->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (1.35.44)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (0.10.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (3.10.10)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (1.11.1.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (9.0.0)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.10/dist-packages (from deepspeed->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (12.560.30)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers>=0.30.3->-r CogVideo/requirements.txt (line 1)) (3.20.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.4.0->-r CogVideo/requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from webdataset->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.44.0->-r CogVideo/requirements.txt (line 9)) (0.1.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->SwissArmyTransformer>=0.4.12->-r CogVideo/requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Set Up the Environment\n",
        "We'll make sure the CogVideo module is accessible in our Python path by adding it manually. Additionally, we'll check if a GPU is available (which is highly recommended for this task)."
      ],
      "metadata": {
        "id": "aZ5WIJtarFKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Add CogVideo to Python path\n",
        "sys.path.append('/content/CogVideo')  # Adjust this path if required\n",
        "\n",
        "# Set an environment variable to avoid memory fragmentation issues\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Check if a GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available, using CPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeG3Pa4brMXf",
        "outputId": "b56013ea-35e6-453f-9ec3-3971a565e47c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Import Required Libraries\n",
        "Next, we'll import the necessary modules for video generation and memory management.\n",
        "\n",
        "Note: Clearing the CUDA cache is important to avoid memory overflow during large operations like video generation."
      ],
      "metadata": {
        "id": "C8guNI_crQ-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as display\n",
        "import numpy as np\n",
        "from torch.quantization import quantize_dynamic\n",
        "\n",
        "# Import necessary classes from the inference module\n",
        "from inference.cli_demo import generate_video  # Adjusted import based on the directory structure\n",
        "from diffusers import CogVideoXPipeline, CogVideoXVideoToVideoPipeline\n",
        "\n",
        "# Clear CUDA cache to free up memory\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "7j8tyl48rUoW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Model Quantization for Efficiency\n",
        "Here, we define a function to quantize the model using dynamic quantization to reduce memory usage and improve efficiency.\n",
        "\n",
        "Explanation: Quantization helps reduce the memory footprint of the model, which is particularly useful when working in environments with limited resources, such as Google Colab."
      ],
      "metadata": {
        "id": "EqOJC6VFre2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the quantization function to optimize the model for lower memory usage\n",
        "def quantize_model(model):\n",
        "    model = quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)\n",
        "    return model"
      ],
      "metadata": {
        "id": "h1AHXM0crk21"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Define the Text-to-Video Generation Function\n",
        "In this section, we define the main function that will generate the video based on a given text prompt."
      ],
      "metadata": {
        "id": "yzr6zdlwrvVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast\n",
        "\n",
        "def generate_video_wrapper(prompt, model_id=\"THUDM/CogVideoX-2b\", dtype=torch.float16, num_frames=30):\n",
        "    \"\"\"\n",
        "    Generates a video based on the text prompt using CogVideo with optimizations for Colab T4.\n",
        "\n",
        "    Args:\n",
        "    - prompt (str): The text description for video generation.\n",
        "    - model_id (str): The Hugging Face model ID. Defaults to \"THUDM/CogVideoX-2b\".\n",
        "    - dtype (torch.dtype): The data type for the model. Defaults to torch.float16.\n",
        "    - num_frames (int): Number of frames to generate.\n",
        "\n",
        "    Returns:\n",
        "    - numpy array: Video in NumPy format for display.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the pipeline directly from the Hugging Face Hub\n",
        "        pipe = CogVideoXPipeline.from_pretrained(model_id, torch_dtype=dtype).to(device)\n",
        "\n",
        "        # Quantize the model to save memory\n",
        "        pipe = quantize_model(pipe)\n",
        "\n",
        "        # List to hold generated frames\n",
        "        video_frames = []\n",
        "\n",
        "        # Generate frames iteratively to avoid memory overflow\n",
        "        for frame_idx in range(num_frames):\n",
        "            with autocast():\n",
        "                # Generate the current frame\n",
        "                video_tensor = pipe(prompt).frames.to(device)\n",
        "\n",
        "            # Convert tensor to NumPy array\n",
        "            video_np = video_tensor.cpu().numpy()\n",
        "            video_frames.append(np.clip(video_np * 255, 0, 255).astype(np.uint8))\n",
        "\n",
        "            # Clear cache after each frame to prevent memory fragmentation\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Combine frames into a single video\n",
        "        video_np = np.stack(video_frames)\n",
        "        return video_np\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during video generation: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "bcXEnmS5rxwR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "\n",
        "\n",
        "*   This function takes a text prompt, uses the CogVideo model to generate frames iteratively (to avoid memory issues), and finally combines them into a single video.\n",
        "*   We use torch.cuda.amp.autocast() to speed up computation and reduce memory usage.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UsW1kdSLr59e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Test the Model with a Sample Prompt\n",
        "Now, let's generate a video based on a sample text description"
      ],
      "metadata": {
        "id": "ubq6auBxsF_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text prompt for video generation\n",
        "prompt = \"A beautiful waterfall in a forest\"\n",
        "\n",
        "# Generate a video with 20 frames (can be adjusted based on available resources)\n",
        "video = generate_video_wrapper(prompt, num_frames=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "31b698e587364030bc0a51b356a5f1d0",
            "e352b3827702417098aedcd11c4256fa",
            "1a43a3ae88ef4dabbcc4b092bbd716de",
            "d008ced78b6948cc9b5a2312aca21b64",
            "f0a6bccdafc848a9a0a200290cca73d5",
            "22421f7e11854b408dbbe06ab38308c7",
            "48693660f6154dd1b77ec46789b3ed0a",
            "d862794c6b0b48ce9698bbfe2ce831f9",
            "df8035571e274d349265dedbca22ece0",
            "a95b8a23d3f8421cafb70b01e30742d9",
            "51a6b943e1d7442cbc790c5863f94327",
            "f1215a7adf96454c9d8e76dd14511c9f",
            "eeac6bcaba6841a690faad33ff8665a6",
            "438fba0787a1454aa84f90415ddff3ec",
            "2f1aba318676413e878b7e88d6881578",
            "ca9ddaa474a4495e9dc982aa158cf830",
            "9e7a3f46628449ee98d249bd566fb05a",
            "2da07839b37348ba821945b49db3f012",
            "89b90f21c1054e5d92a07c0a7a8d8a4b",
            "527e66130ea3431db230e364e1427d73",
            "ee52cda6436a4fa7bc7a7f54877c8154",
            "8ee637498d7b42e3be7efeeb3b4d12ee"
          ]
        },
        "id": "u2L1yQsxsOx6",
        "outputId": "bc337c1a-3b19-4025-9fea-b469d9b985d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31b698e587364030bc0a51b356a5f1d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1215a7adf96454c9d8e76dd14511c9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during video generation: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 19.06 MiB is free. Process 18576 has 14.73 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 18.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We use the generate_video_wrapper() function to create a video based on the text prompt \"A beautiful waterfall in a forest.\" The number of frames is reduced to 5 to avoid potential memory issues on Colab. But unfortunately we get CUDA out of memory error despite all efforts. May be this code should work fine on Colab Pro or a higher end NVIDIA GPU which unfortunately I dont have access to. I promise I will update this notebook once I have such access"
      ],
      "metadata": {
        "id": "GvsToXH4sUbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Display the Generated Video\n",
        "Finally, let's display the generated video directly in the notebook."
      ],
      "metadata": {
        "id": "_27xtq46sbat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If video was generated successfully, display it in the notebook\n",
        "if video is not None:\n",
        "    display.display(display.Video(video, embed=True))\n",
        "else:\n",
        "    print(\"Failed to generate video.\")"
      ],
      "metadata": {
        "id": "W7b_PGursiff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We use IPython.display to embed and display the generated video directly within the notebook. If the video generation fails, an error message is printed.\n",
        "\n",
        "P.S: Sorry we didnt see the Video"
      ],
      "metadata": {
        "id": "3wMKbtQTslPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Conclusion***\n",
        "In this notebook, we successfully set up and used the CogVideo model to generate a video based on a text prompt. We've also optimized the model using quantization to reduce memory usage and ensure smooth execution in a limited resource environment like Google Colab, but unfortunately we are limited by the hardware capabilities in Colab Free Tier."
      ],
      "metadata": {
        "id": "4P8m-18JspaW"
      }
    }
  ]
}